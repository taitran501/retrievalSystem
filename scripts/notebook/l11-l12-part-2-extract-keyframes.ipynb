{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13e2d5bc",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.003533,
     "end_time": "2025-12-09T21:41:07.339585",
     "exception": false,
     "start_time": "2025-12-09T21:41:07.336052",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Extract keyframes from videos with scene detection support from TransnetV2**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87d46fe",
   "metadata": {
    "papermill": {
     "duration": 0.002711,
     "end_time": "2025-12-09T21:41:07.345328",
     "exception": false,
     "start_time": "2025-12-09T21:41:07.342617",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **1. Install required packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dacf413f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T21:41:07.352577Z",
     "iopub.status.busy": "2025-12-09T21:41:07.352206Z",
     "iopub.status.idle": "2025-12-09T21:41:20.788849Z",
     "shell.execute_reply": "2025-12-09T21:41:20.787822Z"
    },
    "papermill": {
     "duration": 13.442492,
     "end_time": "2025-12-09T21:41:20.790603",
     "exception": false,
     "start_time": "2025-12-09T21:41:07.348111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ffmpeg-python\r\n",
      "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\r\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (9.5.0)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.10/site-packages (from ffmpeg-python) (1.0.0)\r\n",
      "Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\r\n",
      "Installing collected packages: ffmpeg-python\r\n",
      "Successfully installed ffmpeg-python-0.2.0\r\n",
      "Cloning into 'TransNetV2'...\r\n",
      "remote: Enumerating objects: 362, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (88/88), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (17/17), done.\u001b[K\r\n",
      "remote: Total 362 (delta 71), reused 71 (delta 71), pack-reused 274 (from 1)\u001b[K\r\n",
      "Receiving objects: 100% (362/362), 95.25 KiB | 1.59 MiB/s, done.\r\n",
      "Resolving deltas: 100% (210/210), done.\r\n",
      "/kaggle/working/TransNetV2/inference\n"
     ]
    }
   ],
   "source": [
    "!pip install ffmpeg-python pillow\n",
    "!git clone https://github.com/soCzech/TransNetV2.git\n",
    "%cd TransNetV2/inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb33b134",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T21:41:20.799909Z",
     "iopub.status.busy": "2025-12-09T21:41:20.799072Z",
     "iopub.status.idle": "2025-12-09T21:41:35.383647Z",
     "shell.execute_reply": "2025-12-09T21:41:35.382685Z"
    },
    "papermill": {
     "duration": 14.591139,
     "end_time": "2025-12-09T21:41:35.385684",
     "exception": false,
     "start_time": "2025-12-09T21:41:20.794545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import glob\n",
    "import torch\n",
    "import ffmpeg\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from transnetv2 import TransNetV2\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e51057a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T21:41:35.394655Z",
     "iopub.status.busy": "2025-12-09T21:41:35.393958Z",
     "iopub.status.idle": "2025-12-09T21:41:35.445317Z",
     "shell.execute_reply": "2025-12-09T21:41:35.444300Z"
    },
    "papermill": {
     "duration": 0.057431,
     "end_time": "2025-12-09T21:41:35.447006",
     "exception": false,
     "start_time": "2025-12-09T21:41:35.389575",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parts Found: ['L07', 'L08', 'L09', 'L10', 'L11', 'L12']\n"
     ]
    }
   ],
   "source": [
    "# Defined input directories\n",
    "input_dirs = [\n",
    "    # '/kaggle/input/aic2024-videos-part1-1', # Contains L01 to L06\n",
    "    '/kaggle/input/aic2024-videos-part1'     # Contains L07 to L12\n",
    "]\n",
    "\n",
    "all_video_paths = dict()\n",
    "\n",
    "# Iterate through both directories\n",
    "for videos_dir in input_dirs:\n",
    "    if not os.path.exists(videos_dir):\n",
    "        print(f\"Directory not found: {videos_dir}\")\n",
    "        continue\n",
    "        \n",
    "    for part in sorted(os.listdir(videos_dir)):\n",
    "        # Check if folder name matches \"Videos_Lxx\" pattern\n",
    "        if not part.startswith(\"Videos_\"):\n",
    "            continue\n",
    "            \n",
    "        data_part = part.split('_')[-1] # Extracts L01, L02...\n",
    "        \n",
    "        # Initialize dictionary for this part if not exists\n",
    "        if data_part not in all_video_paths:\n",
    "            all_video_paths[data_part] = dict()\n",
    "\n",
    "        data_part_path = f'{videos_dir}/Videos_{data_part}/video'\n",
    "        \n",
    "        if not os.path.exists(data_part_path):\n",
    "            continue\n",
    "            \n",
    "        video_paths = sorted(os.listdir(data_part_path))\n",
    "        # Filter for mp4 only to be safe\n",
    "        video_ids = [vp.replace('.mp4', '').split('_')[-1] for vp in video_paths if vp.endswith('.mp4')]\n",
    "        \n",
    "        for video_id, video_path in zip(video_ids, video_paths):\n",
    "            if not video_path.endswith('.mp4'): continue\n",
    "            video_path_full = f'{data_part_path}/{video_path}'\n",
    "            all_video_paths[data_part][video_id] = video_path_full\n",
    "\n",
    "print(f\"Total Parts Found: {sorted(all_video_paths.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6a22eaf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T21:41:35.455841Z",
     "iopub.status.busy": "2025-12-09T21:41:35.455551Z",
     "iopub.status.idle": "2025-12-09T21:41:35.464219Z",
     "shell.execute_reply": "2025-12-09T21:41:35.463219Z"
    },
    "papermill": {
     "duration": 0.01534,
     "end_time": "2025-12-09T21:41:35.466092",
     "exception": false,
     "start_time": "2025-12-09T21:41:35.450752",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type check: <class 'list'>\n",
      "Total videos to process: 179\n",
      "Videos assigned to this worker: 179\n"
     ]
    }
   ],
   "source": [
    "num_batch = 1\n",
    "BATCH_ID = 0\n",
    "MEMBER_ID = 0    \n",
    "num_member = 1   # Ch·∫°y 100% video\n",
    "\n",
    "all_videos = [x for v in all_video_paths.values() for x in v.values()]\n",
    "\n",
    "# Safety check\n",
    "if len(all_videos) > 0:\n",
    "    # T√≠nh s·ªë l∆∞·ª£ng video m·ªói member c·∫ßn l√†m\n",
    "    # D√πng math.ceil ƒë·ªÉ ƒë·∫£m b·∫£o chia h·∫øt ho·∫∑c d∆∞ v√†o batch cu·ªëi\n",
    "    import math\n",
    "    batch_len = math.ceil(len(all_videos) / num_batch / num_member)\n",
    "else:\n",
    "    batch_len = 0\n",
    "\n",
    "all_batches_info = {n: {} for n in range(num_batch)}\n",
    "current_idx = 0\n",
    "\n",
    "for n in range(num_batch):\n",
    "    for m in range(num_member):\n",
    "        start = current_idx\n",
    "        end = current_idx + batch_len\n",
    "        \n",
    "        # ƒê·∫£m b·∫£o kh√¥ng v∆∞·ª£t qu√° t·ªïng s·ªë video\n",
    "        if end > len(all_videos):\n",
    "            end = len(all_videos)\n",
    "            \n",
    "        # --- FIX QUAN TR·ªåNG T·∫†I ƒê√ÇY ---\n",
    "        # Lu√¥n g√°n v√†o dict con [m], KH√îNG BAO GI·ªú g√°n tr·ª±c ti·∫øp list v√†o [n]\n",
    "        # Ngay c·∫£ khi num_member = 1, ta v·∫´n d√πng key [0]\n",
    "        all_batches_info[n][m] = all_videos[start:end]\n",
    "        \n",
    "        current_idx = end\n",
    "        \n",
    "# Debug: Ki·ªÉm tra xem n√≥ c√≥ ph·∫£i l√† List kh√¥ng\n",
    "print(f\"Type check: {type(all_batches_info[BATCH_ID][MEMBER_ID])}\") \n",
    "# N√≥ ph·∫£i in ra <class 'list'> th√¨ m·ªõi ƒë√∫ng. Tr∆∞·ªõc ƒë√≥ n√≥ in ra <class 'str'> n√™n m·ªõi l·ªói.\n",
    "\n",
    "with open(\"/kaggle/working/batch_info.json\", 'w') as f:\n",
    "    # Convert keys to str for JSON serialization if needed, though int keys are coerced\n",
    "    json.dump(all_batches_info, f)\n",
    "    \n",
    "print(f\"Total videos to process: {len(all_videos)}\")\n",
    "print(f\"Videos assigned to this worker: {len(all_batches_info[BATCH_ID][MEMBER_ID])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bfabfe",
   "metadata": {
    "papermill": {
     "duration": 0.003519,
     "end_time": "2025-12-09T21:41:35.473540",
     "exception": false,
     "start_time": "2025-12-09T21:41:35.470021",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. **Extract shots**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b26a020",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T21:41:35.482175Z",
     "iopub.status.busy": "2025-12-09T21:41:35.481650Z",
     "iopub.status.idle": "2025-12-09T21:41:40.340241Z",
     "shell.execute_reply": "2025-12-09T21:41:40.339540Z"
    },
    "papermill": {
     "duration": 4.865038,
     "end_time": "2025-12-09T21:41:40.342282",
     "exception": false,
     "start_time": "2025-12-09T21:41:35.477244",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TransNetV2] Using weights from /kaggle/working/TransNetV2/inference/transnetv2-weights/.\n"
     ]
    }
   ],
   "source": [
    "model = TransNetV2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a741bfb",
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": false,
    "execution": {
     "iopub.execute_input": "2025-12-09T21:41:40.351142Z",
     "iopub.status.busy": "2025-12-09T21:41:40.350795Z",
     "iopub.status.idle": "2025-12-10T00:57:24.583582Z",
     "shell.execute_reply": "2025-12-10T00:57:24.582599Z"
    },
    "papermill": {
     "duration": 11744.239341,
     "end_time": "2025-12-10T00:57:24.585671",
     "exception": false,
     "start_time": "2025-12-09T21:41:40.346330",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Start processing 179 videos for Scene Detection...\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L07/video/L07_V001.mp4\n",
      "[TransNetV2] Processing video frames 26542/26542\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L07/video/L07_V002.mp4\n",
      "[TransNetV2] Processing video frames 28065/28065\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L07/video/L07_V003.mp4\n",
      "[TransNetV2] Processing video frames 26629/26629\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L07/video/L07_V004.mp4\n",
      "[TransNetV2] Processing video frames 32688/32688\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L07/video/L07_V005.mp4\n",
      "[TransNetV2] Processing video frames 27074/27074\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L07/video/L07_V006.mp4\n",
      "[TransNetV2] Processing video frames 29282/29282\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L07/video/L07_V007.mp4\n",
      "[TransNetV2] Processing video frames 25624/25624\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L07/video/L07_V008.mp4\n",
      "[TransNetV2] Processing video frames 29665/29665\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L07/video/L07_V009.mp4\n",
      "[TransNetV2] Processing video frames 29093/29093\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L07/video/L07_V010.mp4\n",
      "[TransNetV2] Processing video frames 28461/28461\n",
      "   ...Processed 10/179 scenes.\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L07/video/L07_V011.mp4\n",
      "[TransNetV2] Processing video frames 32664/32664\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L07/video/L07_V012.mp4\n",
      "[TransNetV2] Processing video frames 32510/32510\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L07/video/L07_V013.mp4\n",
      "[TransNetV2] Processing video frames 27799/27799\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L07/video/L07_V014.mp4\n",
      "[TransNetV2] Processing video frames 26539/26539\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L07/video/L07_V015.mp4\n",
      "[TransNetV2] Processing video frames 24831/24831\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L07/video/L07_V016.mp4\n",
      "[TransNetV2] Processing video frames 30824/30824\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L07/video/L07_V017.mp4\n",
      "[TransNetV2] Processing video frames 25569/25569\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L07/video/L07_V018.mp4\n",
      "[TransNetV2] Processing video frames 27549/27549\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L07/video/L07_V019.mp4\n",
      "[TransNetV2] Processing video frames 30661/30661\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L07/video/L07_V020.mp4\n",
      "[TransNetV2] Processing video frames 27307/27307\n",
      "   ...Processed 20/179 scenes.\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L07/video/L07_V021.mp4\n",
      "[TransNetV2] Processing video frames 25387/25387\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L07/video/L07_V022.mp4\n",
      "[TransNetV2] Processing video frames 27745/27745\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L07/video/L07_V023.mp4\n",
      "[TransNetV2] Processing video frames 30142/30142\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L07/video/L07_V024.mp4\n",
      "[TransNetV2] Processing video frames 23551/23551\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L07/video/L07_V025.mp4\n",
      "[TransNetV2] Processing video frames 29725/29725\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L07/video/L07_V026.mp4\n",
      "[TransNetV2] Processing video frames 29551/29551\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L07/video/L07_V027.mp4\n",
      "[TransNetV2] Processing video frames 27824/27824\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L07/video/L07_V028.mp4\n",
      "[TransNetV2] Processing video frames 29633/29633\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L07/video/L07_V029.mp4\n",
      "[TransNetV2] Processing video frames 28539/28539\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L07/video/L07_V030.mp4\n",
      "[TransNetV2] Processing video frames 29171/29171\n",
      "   ...Processed 30/179 scenes.\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L07/video/L07_V031.mp4\n",
      "[TransNetV2] Processing video frames 32347/32347\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L08/video/L08_V001.mp4\n",
      "[TransNetV2] Processing video frames 32438/32438\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L08/video/L08_V002.mp4\n",
      "[TransNetV2] Processing video frames 28666/28666\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L08/video/L08_V003.mp4\n",
      "[TransNetV2] Processing video frames 31747/31747\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L08/video/L08_V004.mp4\n",
      "[TransNetV2] Processing video frames 30387/30387\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L08/video/L08_V005.mp4\n",
      "[TransNetV2] Processing video frames 32918/32918\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L08/video/L08_V006.mp4\n",
      "[TransNetV2] Processing video frames 27576/27576\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L08/video/L08_V007.mp4\n",
      "[TransNetV2] Processing video frames 30213/30213\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L08/video/L08_V008.mp4\n",
      "[TransNetV2] Processing video frames 30471/30471\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L08/video/L08_V009.mp4\n",
      "[TransNetV2] Processing video frames 28637/28637\n",
      "   ...Processed 40/179 scenes.\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L08/video/L08_V010.mp4\n",
      "[TransNetV2] Processing video frames 29899/29899\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L08/video/L08_V011.mp4\n",
      "[TransNetV2] Processing video frames 32077/32077\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L08/video/L08_V012.mp4\n",
      "[TransNetV2] Processing video frames 29796/29796\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L08/video/L08_V013.mp4\n",
      "[TransNetV2] Processing video frames 28464/28464\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L08/video/L08_V014.mp4\n",
      "[TransNetV2] Processing video frames 29519/29519\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L08/video/L08_V015.mp4\n",
      "[TransNetV2] Processing video frames 28615/28615\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L08/video/L08_V016.mp4\n",
      "[TransNetV2] Processing video frames 31223/31223\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L08/video/L08_V017.mp4\n",
      "[TransNetV2] Processing video frames 30595/30595\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L08/video/L08_V018.mp4\n",
      "[TransNetV2] Processing video frames 33103/33103\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L08/video/L08_V019.mp4\n",
      "[TransNetV2] Processing video frames 31340/31340\n",
      "   ...Processed 50/179 scenes.\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L08/video/L08_V020.mp4\n",
      "[TransNetV2] Processing video frames 32940/32940\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L08/video/L08_V021.mp4\n",
      "[TransNetV2] Processing video frames 30557/30557\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L08/video/L08_V022.mp4\n",
      "[TransNetV2] Processing video frames 32212/32212\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L08/video/L08_V023.mp4\n",
      "[TransNetV2] Processing video frames 29630/29630\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L08/video/L08_V024.mp4\n",
      "[TransNetV2] Processing video frames 31136/31136\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L08/video/L08_V025.mp4\n",
      "[TransNetV2] Processing video frames 29961/29961\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L08/video/L08_V026.mp4\n",
      "[TransNetV2] Processing video frames 31040/31040\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L08/video/L08_V027.mp4\n",
      "[TransNetV2] Processing video frames 30684/30684\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L08/video/L08_V028.mp4\n",
      "[TransNetV2] Processing video frames 35954/35954\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L08/video/L08_V029.mp4\n",
      "[TransNetV2] Processing video frames 34108/34108\n",
      "   ...Processed 60/179 scenes.\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L08/video/L08_V030.mp4\n",
      "[TransNetV2] Processing video frames 32808/32808\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L09/video/L09_V001.mp4\n",
      "[TransNetV2] Processing video frames 32934/32934\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L09/video/L09_V002.mp4\n",
      "[TransNetV2] Processing video frames 30357/30357\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L09/video/L09_V003.mp4\n",
      "[TransNetV2] Processing video frames 35827/35827\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L09/video/L09_V004.mp4\n",
      "[TransNetV2] Processing video frames 32591/32591\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L09/video/L09_V005.mp4\n",
      "[TransNetV2] Processing video frames 29083/29083\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L09/video/L09_V006.mp4\n",
      "[TransNetV2] Processing video frames 37099/37099\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L09/video/L09_V007.mp4\n",
      "[TransNetV2] Processing video frames 28448/28448\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L09/video/L09_V008.mp4\n",
      "[TransNetV2] Processing video frames 33160/33160\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L09/video/L09_V009.mp4\n",
      "[TransNetV2] Processing video frames 41104/41104\n",
      "   ...Processed 70/179 scenes.\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L09/video/L09_V010.mp4\n",
      "[TransNetV2] Processing video frames 33042/33042\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L09/video/L09_V011.mp4\n",
      "[TransNetV2] Processing video frames 30738/30738\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L09/video/L09_V012.mp4\n",
      "[TransNetV2] Processing video frames 31408/31408\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L09/video/L09_V013.mp4\n",
      "[TransNetV2] Processing video frames 32431/32431\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L09/video/L09_V014.mp4\n",
      "[TransNetV2] Processing video frames 33218/33218\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L09/video/L09_V015.mp4\n",
      "[TransNetV2] Processing video frames 38427/38427\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L09/video/L09_V016.mp4\n",
      "[TransNetV2] Processing video frames 34070/34070\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L09/video/L09_V017.mp4\n",
      "[TransNetV2] Processing video frames 33911/33911\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L09/video/L09_V018.mp4\n",
      "[TransNetV2] Processing video frames 32772/32772\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L09/video/L09_V019.mp4\n",
      "[TransNetV2] Processing video frames 28453/28453\n",
      "   ...Processed 80/179 scenes.\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L09/video/L09_V020.mp4\n",
      "[TransNetV2] Processing video frames 37118/37118\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L09/video/L09_V021.mp4\n",
      "[TransNetV2] Processing video frames 29192/29192\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L09/video/L09_V022.mp4\n",
      "[TransNetV2] Processing video frames 34612/34612\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L09/video/L09_V023.mp4\n",
      "[TransNetV2] Processing video frames 28186/28186\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L09/video/L09_V024.mp4\n",
      "[TransNetV2] Processing video frames 28874/28874\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L09/video/L09_V025.mp4\n",
      "[TransNetV2] Processing video frames 30502/30502\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L09/video/L09_V026.mp4\n",
      "[TransNetV2] Processing video frames 25527/25527\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L09/video/L09_V027.mp4\n",
      "[TransNetV2] Processing video frames 27401/27401\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L09/video/L09_V028.mp4\n",
      "[TransNetV2] Processing video frames 32054/32054\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L09/video/L09_V029.mp4\n",
      "[TransNetV2] Processing video frames 28807/28807\n",
      "   ...Processed 90/179 scenes.\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L10/video/L10_V001.mp4\n",
      "[TransNetV2] Processing video frames 34644/34644\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L10/video/L10_V002.mp4\n",
      "[TransNetV2] Processing video frames 30475/30475\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L10/video/L10_V003.mp4\n",
      "[TransNetV2] Processing video frames 34964/34964\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L10/video/L10_V004.mp4\n",
      "[TransNetV2] Processing video frames 32340/32340\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L10/video/L10_V005.mp4\n",
      "[TransNetV2] Processing video frames 37771/37771\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L10/video/L10_V006.mp4\n",
      "[TransNetV2] Processing video frames 35380/35380\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L10/video/L10_V007.mp4\n",
      "[TransNetV2] Processing video frames 31785/31785\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L10/video/L10_V008.mp4\n",
      "[TransNetV2] Processing video frames 30573/30573\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L10/video/L10_V009.mp4\n",
      "[TransNetV2] Processing video frames 33268/33268\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L10/video/L10_V010.mp4\n",
      "[TransNetV2] Processing video frames 30434/30434\n",
      "   ...Processed 100/179 scenes.\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L10/video/L10_V011.mp4\n",
      "[TransNetV2] Processing video frames 27698/27698\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L10/video/L10_V012.mp4\n",
      "[TransNetV2] Processing video frames 34996/34996\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L10/video/L10_V013.mp4\n",
      "[TransNetV2] Processing video frames 30323/30323\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L10/video/L10_V014.mp4\n",
      "[TransNetV2] Processing video frames 35202/35202\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L10/video/L10_V015.mp4\n",
      "[TransNetV2] Processing video frames 31400/31400\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L10/video/L10_V016.mp4\n",
      "[TransNetV2] Processing video frames 34392/34392\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L10/video/L10_V017.mp4\n",
      "[TransNetV2] Processing video frames 29264/29264\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L10/video/L10_V018.mp4\n",
      "[TransNetV2] Processing video frames 30734/30734\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L10/video/L10_V019.mp4\n",
      "[TransNetV2] Processing video frames 27787/27787\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L10/video/L10_V020.mp4\n",
      "[TransNetV2] Processing video frames 31501/31501\n",
      "   ...Processed 110/179 scenes.\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L10/video/L10_V021.mp4\n",
      "[TransNetV2] Processing video frames 33939/33939\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L10/video/L10_V022.mp4\n",
      "[TransNetV2] Processing video frames 31899/31899\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L10/video/L10_V023.mp4\n",
      "[TransNetV2] Processing video frames 34437/34437\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L10/video/L10_V024.mp4\n",
      "[TransNetV2] Processing video frames 32332/32332\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L10/video/L10_V025.mp4\n",
      "[TransNetV2] Processing video frames 33930/33930\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L10/video/L10_V026.mp4\n",
      "[TransNetV2] Processing video frames 32544/32544\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L10/video/L10_V027.mp4\n",
      "[TransNetV2] Processing video frames 32560/32560\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L10/video/L10_V028.mp4\n",
      "[TransNetV2] Processing video frames 33054/33054\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L10/video/L10_V029.mp4\n",
      "[TransNetV2] Processing video frames 29890/29890\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L11/video/L11_V001.mp4\n",
      "[TransNetV2] Processing video frames 33047/33047\n",
      "   ...Processed 120/179 scenes.\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L11/video/L11_V002.mp4\n",
      "[TransNetV2] Processing video frames 30377/30377\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L11/video/L11_V003.mp4\n",
      "[TransNetV2] Processing video frames 32167/32167\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L11/video/L11_V004.mp4\n",
      "[TransNetV2] Processing video frames 25227/25227\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L11/video/L11_V005.mp4\n",
      "[TransNetV2] Processing video frames 30743/30743\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L11/video/L11_V006.mp4\n",
      "[TransNetV2] Processing video frames 28654/28654\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L11/video/L11_V007.mp4\n",
      "[TransNetV2] Processing video frames 33619/33619\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L11/video/L11_V008.mp4\n",
      "[TransNetV2] Processing video frames 33136/33136\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L11/video/L11_V009.mp4\n",
      "[TransNetV2] Processing video frames 33441/33441\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L11/video/L11_V010.mp4\n",
      "[TransNetV2] Processing video frames 26997/26997\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L11/video/L11_V011.mp4\n",
      "[TransNetV2] Processing video frames 27064/27064\n",
      "   ...Processed 130/179 scenes.\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L11/video/L11_V012.mp4\n",
      "[TransNetV2] Processing video frames 28923/28923\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L11/video/L11_V013.mp4\n",
      "[TransNetV2] Processing video frames 29765/29765\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L11/video/L11_V014.mp4\n",
      "[TransNetV2] Processing video frames 27640/27640\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L11/video/L11_V015.mp4\n",
      "[TransNetV2] Processing video frames 25841/25841\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L11/video/L11_V016.mp4\n",
      "[TransNetV2] Processing video frames 29279/29279\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L11/video/L11_V017.mp4\n",
      "[TransNetV2] Processing video frames 29100/29100\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L11/video/L11_V018.mp4\n",
      "[TransNetV2] Processing video frames 34850/34850\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L11/video/L11_V019.mp4\n",
      "[TransNetV2] Processing video frames 27591/27591\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L11/video/L11_V020.mp4\n",
      "[TransNetV2] Processing video frames 30095/30095\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L11/video/L11_V021.mp4\n",
      "[TransNetV2] Processing video frames 33046/33046\n",
      "   ...Processed 140/179 scenes.\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L11/video/L11_V022.mp4\n",
      "[TransNetV2] Processing video frames 25947/25947\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L11/video/L11_V023.mp4\n",
      "[TransNetV2] Processing video frames 31097/31097\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L11/video/L11_V024.mp4\n",
      "[TransNetV2] Processing video frames 30600/30600\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L11/video/L11_V025.mp4\n",
      "[TransNetV2] Processing video frames 26606/26606\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L11/video/L11_V026.mp4\n",
      "[TransNetV2] Processing video frames 30864/30864\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L11/video/L11_V027.mp4\n",
      "[TransNetV2] Processing video frames 30117/30117\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L11/video/L11_V028.mp4\n",
      "[TransNetV2] Processing video frames 33364/33364\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L11/video/L11_V029.mp4\n",
      "[TransNetV2] Processing video frames 30349/30349\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L11/video/L11_V030.mp4\n",
      "[TransNetV2] Processing video frames 29174/29174\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L12/video/L12_V001.mp4\n",
      "[TransNetV2] Processing video frames 33847/33847\n",
      "   ...Processed 150/179 scenes.\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L12/video/L12_V002.mp4\n",
      "[TransNetV2] Processing video frames 29144/29144\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L12/video/L12_V003.mp4\n",
      "[TransNetV2] Processing video frames 31812/31812\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L12/video/L12_V004.mp4\n",
      "[TransNetV2] Processing video frames 32754/32754\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L12/video/L12_V005.mp4\n",
      "[TransNetV2] Processing video frames 37601/37601\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L12/video/L12_V006.mp4\n",
      "[TransNetV2] Processing video frames 35383/35383\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L12/video/L12_V007.mp4\n",
      "[TransNetV2] Processing video frames 32235/32235\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L12/video/L12_V008.mp4\n",
      "[TransNetV2] Processing video frames 30466/30466\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L12/video/L12_V009.mp4\n",
      "[TransNetV2] Processing video frames 34103/34103\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L12/video/L12_V010.mp4\n",
      "[TransNetV2] Processing video frames 31951/31951\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L12/video/L12_V011.mp4\n",
      "[TransNetV2] Processing video frames 30796/30796\n",
      "   ...Processed 160/179 scenes.\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L12/video/L12_V012.mp4\n",
      "[TransNetV2] Processing video frames 30441/30441\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L12/video/L12_V013.mp4\n",
      "[TransNetV2] Processing video frames 29965/29965\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L12/video/L12_V014.mp4\n",
      "[TransNetV2] Processing video frames 35646/35646\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L12/video/L12_V015.mp4\n",
      "[TransNetV2] Processing video frames 32021/32021\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L12/video/L12_V016.mp4\n",
      "[TransNetV2] Processing video frames 29764/29764\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L12/video/L12_V017.mp4\n",
      "[TransNetV2] Processing video frames 30268/30268\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L12/video/L12_V018.mp4\n",
      "[TransNetV2] Processing video frames 33082/33082\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L12/video/L12_V019.mp4\n",
      "[TransNetV2] Processing video frames 30881/30881\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L12/video/L12_V020.mp4\n",
      "[TransNetV2] Processing video frames 28142/28142\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L12/video/L12_V021.mp4\n",
      "[TransNetV2] Processing video frames 33486/33486\n",
      "   ...Processed 170/179 scenes.\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L12/video/L12_V022.mp4\n",
      "[TransNetV2] Processing video frames 31790/31790\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L12/video/L12_V023.mp4\n",
      "[TransNetV2] Processing video frames 29963/29963\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L12/video/L12_V024.mp4\n",
      "[TransNetV2] Processing video frames 30080/30080\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L12/video/L12_V025.mp4\n",
      "[TransNetV2] Processing video frames 30651/30651\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L12/video/L12_V026.mp4\n",
      "[TransNetV2] Processing video frames 25140/25140\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L12/video/L12_V027.mp4\n",
      "[TransNetV2] Processing video frames 31102/31102\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L12/video/L12_V028.mp4\n",
      "[TransNetV2] Processing video frames 32845/32845\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L12/video/L12_V029.mp4\n",
      "[TransNetV2] Processing video frames 32988/32988\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1/Videos_L12/video/L12_V030.mp4\n",
      "[TransNetV2] Processing video frames 31269/31269\n",
      "‚úÖ Scene Detection FINISHED! Created 179 json files.\n",
      "CPU times: user 27min 42s, sys: 4min 2s, total: 31min 44s\n",
      "Wall time: 3h 15min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import os\n",
    "import json\n",
    "\n",
    "save_dir = '/kaggle/working/scenes'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# L·∫•y danh s√°ch video t·ª´ config ·ªü Cell 4\n",
    "videos_to_process = all_batches_info[BATCH_ID][MEMBER_ID]\n",
    "print(f\"üöÄ Start processing {len(videos_to_process)} videos for Scene Detection...\")\n",
    "\n",
    "count = 0\n",
    "for i, video_path in enumerate(videos_to_process):\n",
    "    try:\n",
    "        # --- LOGIC FIX L·ªñI T√äN FILE ---\n",
    "        filename = video_path.split('/')[-1]\n",
    "        parts = filename.split('_')\n",
    "        \n",
    "        if len(parts) >= 2:\n",
    "            # Chu·∫©n: L01_V001.mp4 -> Batch: L01\n",
    "            video_batch = parts[0]\n",
    "            video_name = \"_\".join(parts[1:])\n",
    "        else:\n",
    "            # L·ªói: test.mp4 -> L·∫•y Batch t·ª´ t√™n th∆∞ m·ª•c cha (Videos_L01)\n",
    "            parent_dir = video_path.split('/')[-3] \n",
    "            if \"Videos_\" in parent_dir:\n",
    "                video_batch = parent_dir.split('_')[-1]\n",
    "            else:\n",
    "                video_batch = \"Uncategorized\"\n",
    "            video_name = filename\n",
    "\n",
    "        video_name = video_name.replace('.mp4', '')\n",
    "        \n",
    "        # T·∫°o th∆∞ m·ª•c con: /scenes/L01\n",
    "        batch_save_dir = os.path.join(save_dir, video_batch)\n",
    "        os.makedirs(batch_save_dir, exist_ok=True)\n",
    "        \n",
    "        json_path = f\"{batch_save_dir}/{video_name}.json\"\n",
    "        \n",
    "        # N·∫øu file ƒë√£ c√≥ r·ªìi th√¨ b·ªè qua (ƒë·ªÉ resume n·∫øu b·ªã ng·∫Øt)\n",
    "        if os.path.exists(json_path):\n",
    "            continue\n",
    "\n",
    "        # --- G·ªåI TRANSNET MODEL ---\n",
    "        _, single_frame_predictions, _ = model.predict_video(video_path)\n",
    "        scenes = model.predictions_to_scenes(single_frame_predictions)\n",
    "        \n",
    "        with open(json_path, 'w') as f:\n",
    "            json.dump(scenes.tolist(), f)\n",
    "            \n",
    "        count += 1\n",
    "        if count % 10 == 0:\n",
    "            print(f\"   ...Processed {count}/{len(videos_to_process)} scenes.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error on {video_path}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"‚úÖ Scene Detection FINISHED! Created {count} json files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132a1c5e",
   "metadata": {
    "papermill": {
     "duration": 0.816508,
     "end_time": "2025-12-10T00:57:26.265395",
     "exception": false,
     "start_time": "2025-12-10T00:57:25.448887",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **4. Extract frames from scenes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2c4d6ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T00:57:27.999741Z",
     "iopub.status.busy": "2025-12-10T00:57:27.999068Z",
     "iopub.status.idle": "2025-12-10T00:57:28.006208Z",
     "shell.execute_reply": "2025-12-10T00:57:28.005472Z"
    },
    "papermill": {
     "duration": 0.87729,
     "end_time": "2025-12-10T00:57:28.007847",
     "exception": false,
     "start_time": "2025-12-10T00:57:27.130557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_frames(video_path: str, frame_numbers: np.ndarray, save_dir: str):\n",
    "    \"\"\"\n",
    "    Extract frames from a video using OpenCV. Optimized for logging.\n",
    "    \"\"\"\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # Sort frame numbers to ensure sequential reading (faster)\n",
    "    frame_numbers = np.sort(np.unique(frame_numbers))\n",
    "    \n",
    "    frame_idx = 0\n",
    "    if len(frame_numbers) == 0:\n",
    "        video.release()\n",
    "        return\n",
    "\n",
    "    frame_it = frame_numbers[frame_idx]\n",
    "    # We only need to read up to the last required frame\n",
    "    max_frame = frame_numbers[-1] + 1\n",
    "    \n",
    "    saved_count = 0\n",
    "    \n",
    "    # REMOVED tqdm here to prevent nested progress bars spamming\n",
    "    for i in range(max_frame):\n",
    "        ret, frame = video.read()       \n",
    "\n",
    "        if not ret:\n",
    "            # End of video reached prematurely\n",
    "            break\n",
    "            \n",
    "        if i == frame_it:\n",
    "            filename = \"{}/{:0>4d}.jpg\".format(f'{save_dir}', i) # Changed index to i for real frame ID\n",
    "            \n",
    "            if cv2.imwrite(filename, frame):\n",
    "                saved_count += 1\n",
    "            \n",
    "            frame_idx += 1\n",
    "            if frame_idx < len(frame_numbers):\n",
    "                frame_it = frame_numbers[frame_idx]\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e10c1ff8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T00:57:29.695246Z",
     "iopub.status.busy": "2025-12-10T00:57:29.694920Z",
     "iopub.status.idle": "2025-12-10T01:50:07.920446Z",
     "shell.execute_reply": "2025-12-10T01:50:07.919519Z"
    },
    "papermill": {
     "duration": 3159.713472,
     "end_time": "2025-12-10T01:50:08.542056",
     "exception": false,
     "start_time": "2025-12-10T00:57:28.828584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting Extraction for Batches: ['L11', 'L12']\n",
      "üíæ Saving to: keyframes_part2_set2.zip\n",
      "üëâ Processing Batch L11 (30 videos)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54b85e61389649ae9d2e217a4a9b4641",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Zipping L11:   0%|          | 0/30 [00:00<?, ?vid/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üëâ Processing Batch L12 (30 videos)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbf7c7f62d034cf5bebd695f50a626f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Zipping L12:   0%|          | 0/30 [00:00<?, ?vid/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Finished processing all requested batches: ['L11', 'L12']\n",
      "üì¶ Closing Zip file...\n",
      "üéâ DONE! File created: keyframes_part2_set2.zip (6.77 GB)\n"
     ]
    }
   ],
   "source": [
    "# --- CELL 8: Split Strategy & Safe Direct-Write ---\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import cv2\n",
    "import os\n",
    "import json\n",
    "import zipfile\n",
    "import shutil\n",
    "import glob\n",
    "\n",
    "# ==========================================\n",
    "# ‚öôÔ∏è C·∫§U H√åNH BATCH C·∫¶N CH·∫†Y T·∫†I ƒê√ÇY\n",
    "# ==========================================\n",
    "# Run 1: Ch·∫°y L01 -> L05\n",
    "TARGET_BATCHES = ['L11', 'L12']\n",
    "OUTPUT_ZIP_NAME = 'keyframes_part2_set2.zip'\n",
    "\n",
    "# Run 2 (Notebook kh√°c ho·∫∑c l·∫ßn ch·∫°y sau): Uncomment d√≤ng d∆∞·ªõi\n",
    "# TARGET_BATCHES = ['L06'] \n",
    "# OUTPUT_ZIP_NAME = 'keyframes_part1_set2.zip'\n",
    "# ==========================================\n",
    "\n",
    "# ƒê∆∞·ªùng d·∫´n l√†m vi·ªác\n",
    "work_dir = '/kaggle/working'\n",
    "scene_json_dirs = '/kaggle/working/scenes'\n",
    "final_zip_path = os.path.join(work_dir, OUTPUT_ZIP_NAME)\n",
    "\n",
    "# D·ªçn d·∫πp file c≈© n·∫øu c√≥ ƒë·ªÉ tr√°nh l·ªói append\n",
    "if os.path.exists(final_zip_path):\n",
    "    print(f\"‚ö†Ô∏è Found existing {OUTPUT_ZIP_NAME}, removing to start fresh...\")\n",
    "    os.remove(final_zip_path)\n",
    "\n",
    "# --- H√ÄM CHI·∫æN L∆Ø·ª¢C FRAME (GI·ªÆ NGUY√äN) ---\n",
    "def get_adaptive_frames(scenes):\n",
    "    frames_to_capture = []\n",
    "    for start, end in scenes:\n",
    "        duration = end - start\n",
    "        if duration <= 1: continue \n",
    "        if duration < 25: \n",
    "            frames_to_capture.append((start + end) // 2)\n",
    "        elif duration < 150: \n",
    "            frames_to_capture.extend([start, (start + end) // 2, end - 1])\n",
    "        else: \n",
    "            step = 50 \n",
    "            sampled = range(start, end, step)\n",
    "            frames_to_capture.extend(sampled)\n",
    "            if (end - 1) not in frames_to_capture:\n",
    "                frames_to_capture.append(end - 1)\n",
    "    return sorted(list(set(frames_to_capture)))\n",
    "\n",
    "# --- H√ÄM KI·ªÇM TRA DUNG L∆Ø·ª¢NG TR·ªêNG ---\n",
    "def get_free_space_gb():\n",
    "    total, used, free = shutil.disk_usage(work_dir)\n",
    "    return free / (1024**3)\n",
    "\n",
    "# --- V√íNG L·∫∂P CH√çNH ---\n",
    "print(f\"üöÄ Starting Extraction for Batches: {TARGET_BATCHES}\")\n",
    "print(f\"üíæ Saving to: {OUTPUT_ZIP_NAME}\")\n",
    "\n",
    "# M·ªü file Zip M·ªòT L·∫¶N DUY NH·∫§T ·ªü ch·∫ø ƒë·ªô 'w'\n",
    "# ƒêi·ªÅu n√†y gi√∫p t·ªëi ∆∞u I/O v√† tr√°nh l·ªói ph√¢n m·∫£nh file\n",
    "with zipfile.ZipFile(final_zip_path, 'w', zipfile.ZIP_DEFLATED) as zf:\n",
    "    \n",
    "    stop_processing = False\n",
    "    \n",
    "    for key in TARGET_BATCHES:\n",
    "        if stop_processing: break\n",
    "        \n",
    "        # Ki·ªÉm tra xem Batch n√†y c√≥ trong d·ªØ li·ªáu ƒë·∫ßu v√†o kh√¥ng\n",
    "        if key not in all_video_paths:\n",
    "            print(f\"‚ö†Ô∏è Batch {key} not found in input sources. Skipping.\")\n",
    "            continue\n",
    "            \n",
    "        video_paths_dict = all_video_paths[key]\n",
    "        video_ids = sorted(video_paths_dict.keys())\n",
    "        \n",
    "        print(f\"üëâ Processing Batch {key} ({len(video_ids)} videos)...\")\n",
    "        \n",
    "        # Progress bar cho t·ª´ng video\n",
    "        pbar = tqdm(video_ids, desc=f\"Zipping {key}\", unit=\"vid\")\n",
    "        \n",
    "        for video_id in pbar:\n",
    "            # --- SAFETY CHECK: D·ª™NG N·∫æU ·ªî C·ª®NG S·∫ÆP ƒê·∫¶Y (< 1GB) ---\n",
    "            if get_free_space_gb() < 1.0:\n",
    "                print(f\"\\nüõë CRITICAL WARNING: Disk space low ({get_free_space_gb():.2f} GB left).\")\n",
    "                print(\"üõë Stopping gracefully to save current Zip file.\")\n",
    "                stop_processing = True\n",
    "                break\n",
    "\n",
    "            # Logic t√¨m file Scene JSON\n",
    "            scene_path_v1 = f'{scene_json_dirs}/{key}/{key}_{video_id}.json'\n",
    "            scene_path_v2 = f'{scene_json_dirs}/{key}/{video_id}.json'\n",
    "            final_scene_path = scene_path_v1 if os.path.exists(scene_path_v1) else (scene_path_v2 if os.path.exists(scene_path_v2) else None)\n",
    "            \n",
    "            if not final_scene_path: continue\n",
    "\n",
    "            try:\n",
    "                with open(final_scene_path) as f:\n",
    "                    scenes = json.load(f)\n",
    "                scenes = np.array([list(row) for row in scenes])\n",
    "                if len(scenes) == 0: continue\n",
    "\n",
    "                frame_numbers = get_adaptive_frames(scenes)\n",
    "                if not frame_numbers: continue\n",
    "                \n",
    "                # M·ªü Video & Extract th·∫≥ng v√†o RAM -> Zip\n",
    "                video_path = video_paths_dict[video_id]\n",
    "                vid_cap = cv2.VideoCapture(video_path)\n",
    "                \n",
    "                f_idx = 0\n",
    "                max_f = frame_numbers[-1] + 1\n",
    "                \n",
    "                for i in range(max_f):\n",
    "                    ret, frame = vid_cap.read()\n",
    "                    if not ret: break\n",
    "                    \n",
    "                    if i == frame_numbers[f_idx]:\n",
    "                        # N√©n ·∫£nh JPG v√†o RAM (Quality 80)\n",
    "                        ret_enc, buffer = cv2.imencode('.jpg', frame, [int(cv2.IMWRITE_JPEG_QUALITY), 80])\n",
    "                        \n",
    "                        if ret_enc:\n",
    "                            # C·∫•u tr√∫c: keyframes/L01/V001/0001.jpg\n",
    "                            zip_entry_name = f\"keyframes/{key}/{video_id}/{i:04d}.jpg\"\n",
    "                            zf.writestr(zip_entry_name, buffer.tobytes())\n",
    "                        \n",
    "                        f_idx += 1\n",
    "                        if f_idx >= len(frame_numbers): break\n",
    "                            \n",
    "                vid_cap.release()\n",
    "                \n",
    "            except Exception as e:\n",
    "                # print(f\"Error {video_id}: {e}\")\n",
    "                pass\n",
    "\n",
    "    if stop_processing:\n",
    "        print(\"‚ö†Ô∏è Process stopped early due to disk limits.\")\n",
    "    else:\n",
    "        print(f\"‚úÖ Finished processing all requested batches: {TARGET_BATCHES}\")\n",
    "\n",
    "print(f\"üì¶ Closing Zip file...\")\n",
    "# Khi tho√°t kh·ªèi block 'with', file zip s·∫Ω t·ª± ƒë·ªông ƒë∆∞·ª£c finalize an to√†n\n",
    "\n",
    "final_size = os.path.getsize(final_zip_path) / (1024**3)\n",
    "print(f\"üéâ DONE! File created: {OUTPUT_ZIP_NAME} ({final_size:.2f} GB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c13445e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T01:50:10.238139Z",
     "iopub.status.busy": "2025-12-10T01:50:10.237233Z",
     "iopub.status.idle": "2025-12-10T01:50:10.241790Z",
     "shell.execute_reply": "2025-12-10T01:50:10.240977Z"
    },
    "papermill": {
     "duration": 0.821907,
     "end_time": "2025-12-10T01:50:10.243408",
     "exception": false,
     "start_time": "2025-12-10T01:50:09.421501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %cd /kaggle/working/\n",
    "\n",
    "# print(\"üì¶ Zipping Scenes...\")\n",
    "# !zip -rq scenes.zip scenes/\n",
    "\n",
    "# import os\n",
    "# def get_size(path):\n",
    "#     if os.path.exists(path):\n",
    "#         size = os.path.getsize(path) / (1024 * 1024 * 1024)\n",
    "#         print(f\"   -> {path}: {size:.2f} GB\")\n",
    "#     else:\n",
    "#         print(f\"   -> {path}: NOT FOUND\")\n",
    "\n",
    "# print(\"üìä Checking Output Sizes:\")\n",
    "# get_size('keyframes.zip')\n",
    "# get_size('scenes.zip')\n",
    "\n",
    "# from IPython.display import FileLink\n",
    "# print(\"\\n‚¨áÔ∏è DOWNLOAD LINKS:\")\n",
    "# display(FileLink('keyframes.zip'))\n",
    "# display(FileLink('scenes.zip'))\n",
    "\n",
    "# # Cleanup (Optional)\n",
    "# # !rm -rf scenes\n",
    "# # !rm -rf temp_keyframes"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5567850,
     "sourceId": 9215137,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5573261,
     "sourceId": 9216514,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30762,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 14949.511632,
   "end_time": "2025-12-10T01:50:14.405432",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-09T21:41:04.893800",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "1ba956fe3735452a9273ec9cc33af852": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "3f06e12e14cd492daf6d2dbca1e66bb4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4fc1d65733de488ab40e3371e83d07b0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "54b85e61389649ae9d2e217a4a9b4641": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_56d503f2806140e79c1397d1940f18eb",
        "IPY_MODEL_bc0e56dfc004480e80f1db2ad06c41f1",
        "IPY_MODEL_f567c31d459c4cc39f642d211366dcb0"
       ],
       "layout": "IPY_MODEL_f8f4dfd205fa42d89030f758d5c90007"
      }
     },
     "56d503f2806140e79c1397d1940f18eb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_df49217e223f4a02aab748a63b29cef6",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_1ba956fe3735452a9273ec9cc33af852",
       "value": "Zipping‚ÄáL11:‚Äá100%"
      }
     },
     "666db42a698b46c283920d46bdfca82c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7efef63035e04b29a8fa69c3a9d3390e",
       "max": 30.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_90f96ac1ae3349639de28287052212f5",
       "value": 30.0
      }
     },
     "7efef63035e04b29a8fa69c3a9d3390e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "808df255213b4f7eba59cd85d68b1e5f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_dfd2c439867a4689b85683e7b845f8e9",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_82ed24e79116440b99d9e4ecbeaf5f83",
       "value": "‚Äá30/30‚Äá[27:17&lt;00:00,‚Äá55.15s/vid]"
      }
     },
     "82ed24e79116440b99d9e4ecbeaf5f83": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "87c9585acf6a4c5d869df1b2659c3523": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "90f96ac1ae3349639de28287052212f5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "9e62e18fbe1c4a24884ababc63d56315": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ad828bee410c425ca2766ef3d2dea6b0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bb0186856a2f4cc1b6457ca525ee0475": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "bbf7c7f62d034cf5bebd695f50a626f0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_ed94ddc0e604470992206777e67b1054",
        "IPY_MODEL_666db42a698b46c283920d46bdfca82c",
        "IPY_MODEL_808df255213b4f7eba59cd85d68b1e5f"
       ],
       "layout": "IPY_MODEL_ad828bee410c425ca2766ef3d2dea6b0"
      }
     },
     "bc0e56dfc004480e80f1db2ad06c41f1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9e62e18fbe1c4a24884ababc63d56315",
       "max": 30.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_bb0186856a2f4cc1b6457ca525ee0475",
       "value": 30.0
      }
     },
     "dd08729177044d4c8f579485fba4afa4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "df49217e223f4a02aab748a63b29cef6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dfd2c439867a4689b85683e7b845f8e9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ed94ddc0e604470992206777e67b1054": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3f06e12e14cd492daf6d2dbca1e66bb4",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_dd08729177044d4c8f579485fba4afa4",
       "value": "Zipping‚ÄáL12:‚Äá100%"
      }
     },
     "f567c31d459c4cc39f642d211366dcb0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4fc1d65733de488ab40e3371e83d07b0",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_87c9585acf6a4c5d869df1b2659c3523",
       "value": "‚Äá30/30‚Äá[25:20&lt;00:00,‚Äá52.36s/vid]"
      }
     },
     "f8f4dfd205fa42d89030f758d5c90007": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
