{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af50505d",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.0037,
     "end_time": "2025-12-09T21:39:22.922953",
     "exception": false,
     "start_time": "2025-12-09T21:39:22.919253",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Extract keyframes from videos with scene detection support from TransnetV2**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e94f47e",
   "metadata": {
    "papermill": {
     "duration": 0.002725,
     "end_time": "2025-12-09T21:39:22.928810",
     "exception": false,
     "start_time": "2025-12-09T21:39:22.926085",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **1. Install required packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8da64856",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T21:39:22.939088Z",
     "iopub.status.busy": "2025-12-09T21:39:22.938194Z",
     "iopub.status.idle": "2025-12-09T21:39:38.040633Z",
     "shell.execute_reply": "2025-12-09T21:39:38.039542Z"
    },
    "papermill": {
     "duration": 15.110998,
     "end_time": "2025-12-09T21:39:38.042558",
     "exception": false,
     "start_time": "2025-12-09T21:39:22.931560",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ffmpeg-python\r\n",
      "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\r\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (9.5.0)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.10/site-packages (from ffmpeg-python) (1.0.0)\r\n",
      "Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\r\n",
      "Installing collected packages: ffmpeg-python\r\n",
      "Successfully installed ffmpeg-python-0.2.0\r\n",
      "Cloning into 'TransNetV2'...\r\n",
      "remote: Enumerating objects: 362, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (88/88), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (17/17), done.\u001b[K\r\n",
      "remote: Total 362 (delta 71), reused 71 (delta 71), pack-reused 274 (from 1)\u001b[K\r\n",
      "Receiving objects: 100% (362/362), 95.25 KiB | 6.35 MiB/s, done.\r\n",
      "Resolving deltas: 100% (210/210), done.\r\n",
      "/kaggle/working/TransNetV2/inference\n"
     ]
    }
   ],
   "source": [
    "!pip install ffmpeg-python pillow\n",
    "!git clone https://github.com/soCzech/TransNetV2.git\n",
    "%cd TransNetV2/inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4999ed0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T21:39:38.051106Z",
     "iopub.status.busy": "2025-12-09T21:39:38.050820Z",
     "iopub.status.idle": "2025-12-09T21:40:00.649647Z",
     "shell.execute_reply": "2025-12-09T21:40:00.648841Z"
    },
    "papermill": {
     "duration": 22.605431,
     "end_time": "2025-12-09T21:40:00.651807",
     "exception": false,
     "start_time": "2025-12-09T21:39:38.046376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import glob\n",
    "import torch\n",
    "import ffmpeg\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from transnetv2 import TransNetV2\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a04a091",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T21:40:00.660599Z",
     "iopub.status.busy": "2025-12-09T21:40:00.660060Z",
     "iopub.status.idle": "2025-12-09T21:40:00.831752Z",
     "shell.execute_reply": "2025-12-09T21:40:00.830806Z"
    },
    "papermill": {
     "duration": 0.177819,
     "end_time": "2025-12-09T21:40:00.833520",
     "exception": false,
     "start_time": "2025-12-09T21:40:00.655701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parts Found: ['L01', 'L02', 'L03', 'L04', 'L05', 'L06']\n"
     ]
    }
   ],
   "source": [
    "# Defined input directories\n",
    "input_dirs = [\n",
    "    '/kaggle/input/aic2024-videos-part1-1', # Contains L01 to L06\n",
    "    # '/kaggle/input/aic2024-videos-part1'     # Contains L07 to L12\n",
    "]\n",
    "\n",
    "all_video_paths = dict()\n",
    "\n",
    "# Iterate through both directories\n",
    "for videos_dir in input_dirs:\n",
    "    if not os.path.exists(videos_dir):\n",
    "        print(f\"Directory not found: {videos_dir}\")\n",
    "        continue\n",
    "        \n",
    "    for part in sorted(os.listdir(videos_dir)):\n",
    "        # Check if folder name matches \"Videos_Lxx\" pattern\n",
    "        if not part.startswith(\"Videos_\"):\n",
    "            continue\n",
    "            \n",
    "        data_part = part.split('_')[-1] # Extracts L01, L02...\n",
    "        \n",
    "        # Initialize dictionary for this part if not exists\n",
    "        if data_part not in all_video_paths:\n",
    "            all_video_paths[data_part] = dict()\n",
    "\n",
    "        data_part_path = f'{videos_dir}/Videos_{data_part}/video'\n",
    "        \n",
    "        if not os.path.exists(data_part_path):\n",
    "            continue\n",
    "            \n",
    "        video_paths = sorted(os.listdir(data_part_path))\n",
    "        # Filter for mp4 only to be safe\n",
    "        video_ids = [vp.replace('.mp4', '').split('_')[-1] for vp in video_paths if vp.endswith('.mp4')]\n",
    "        \n",
    "        for video_id, video_path in zip(video_ids, video_paths):\n",
    "            if not video_path.endswith('.mp4'): continue\n",
    "            video_path_full = f'{data_part_path}/{video_path}'\n",
    "            all_video_paths[data_part][video_id] = video_path_full\n",
    "\n",
    "print(f\"Total Parts Found: {sorted(all_video_paths.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa68de8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T21:40:00.842803Z",
     "iopub.status.busy": "2025-12-09T21:40:00.842498Z",
     "iopub.status.idle": "2025-12-09T21:40:00.851055Z",
     "shell.execute_reply": "2025-12-09T21:40:00.850210Z"
    },
    "papermill": {
     "duration": 0.015306,
     "end_time": "2025-12-09T21:40:00.852631",
     "exception": false,
     "start_time": "2025-12-09T21:40:00.837325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type check: <class 'list'>\n",
      "Total videos to process: 184\n",
      "Videos assigned to this worker: 184\n"
     ]
    }
   ],
   "source": [
    "num_batch = 1\n",
    "BATCH_ID = 0\n",
    "MEMBER_ID = 0    \n",
    "num_member = 1   # Ch·∫°y 100% video\n",
    "\n",
    "all_videos = [x for v in all_video_paths.values() for x in v.values()]\n",
    "\n",
    "# Safety check\n",
    "if len(all_videos) > 0:\n",
    "    # T√≠nh s·ªë l∆∞·ª£ng video m·ªói member c·∫ßn l√†m\n",
    "    # D√πng math.ceil ƒë·ªÉ ƒë·∫£m b·∫£o chia h·∫øt ho·∫∑c d∆∞ v√†o batch cu·ªëi\n",
    "    import math\n",
    "    batch_len = math.ceil(len(all_videos) / num_batch / num_member)\n",
    "else:\n",
    "    batch_len = 0\n",
    "\n",
    "all_batches_info = {n: {} for n in range(num_batch)}\n",
    "current_idx = 0\n",
    "\n",
    "for n in range(num_batch):\n",
    "    for m in range(num_member):\n",
    "        start = current_idx\n",
    "        end = current_idx + batch_len\n",
    "        \n",
    "        # ƒê·∫£m b·∫£o kh√¥ng v∆∞·ª£t qu√° t·ªïng s·ªë video\n",
    "        if end > len(all_videos):\n",
    "            end = len(all_videos)\n",
    "            \n",
    "        # --- FIX QUAN TR·ªåNG T·∫†I ƒê√ÇY ---\n",
    "        # Lu√¥n g√°n v√†o dict con [m], KH√îNG BAO GI·ªú g√°n tr·ª±c ti·∫øp list v√†o [n]\n",
    "        # Ngay c·∫£ khi num_member = 1, ta v·∫´n d√πng key [0]\n",
    "        all_batches_info[n][m] = all_videos[start:end]\n",
    "        \n",
    "        current_idx = end\n",
    "        \n",
    "# Debug: Ki·ªÉm tra xem n√≥ c√≥ ph·∫£i l√† List kh√¥ng\n",
    "print(f\"Type check: {type(all_batches_info[BATCH_ID][MEMBER_ID])}\") \n",
    "# N√≥ ph·∫£i in ra <class 'list'> th√¨ m·ªõi ƒë√∫ng. Tr∆∞·ªõc ƒë√≥ n√≥ in ra <class 'str'> n√™n m·ªõi l·ªói.\n",
    "\n",
    "with open(\"/kaggle/working/batch_info.json\", 'w') as f:\n",
    "    # Convert keys to str for JSON serialization if needed, though int keys are coerced\n",
    "    json.dump(all_batches_info, f)\n",
    "    \n",
    "print(f\"Total videos to process: {len(all_videos)}\")\n",
    "print(f\"Videos assigned to this worker: {len(all_batches_info[BATCH_ID][MEMBER_ID])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454bdd0c",
   "metadata": {
    "papermill": {
     "duration": 0.003389,
     "end_time": "2025-12-09T21:40:00.859530",
     "exception": false,
     "start_time": "2025-12-09T21:40:00.856141",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. **Extract shots**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fcc24bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T21:40:00.867874Z",
     "iopub.status.busy": "2025-12-09T21:40:00.867649Z",
     "iopub.status.idle": "2025-12-09T21:40:05.719250Z",
     "shell.execute_reply": "2025-12-09T21:40:05.718553Z"
    },
    "papermill": {
     "duration": 4.857676,
     "end_time": "2025-12-09T21:40:05.721133",
     "exception": false,
     "start_time": "2025-12-09T21:40:00.863457",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TransNetV2] Using weights from /kaggle/working/TransNetV2/inference/transnetv2-weights/.\n"
     ]
    }
   ],
   "source": [
    "model = TransNetV2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53932167",
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": false,
    "execution": {
     "iopub.execute_input": "2025-12-09T21:40:05.729548Z",
     "iopub.status.busy": "2025-12-09T21:40:05.729251Z",
     "iopub.status.idle": "2025-12-10T00:52:10.496596Z",
     "shell.execute_reply": "2025-12-10T00:52:10.495590Z"
    },
    "papermill": {
     "duration": 11524.773415,
     "end_time": "2025-12-10T00:52:10.498372",
     "exception": false,
     "start_time": "2025-12-09T21:40:05.724957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Start processing 184 videos for Scene Detection...\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L01/video/L01_V001.mp4\n",
      "[TransNetV2] Processing video frames 31665/31665\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L01/video/L01_V002.mp4\n",
      "[TransNetV2] Processing video frames 24337/24337\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L01/video/L01_V003.mp4\n",
      "[TransNetV2] Processing video frames 30668/30668\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L01/video/L01_V004.mp4\n",
      "[TransNetV2] Processing video frames 23027/23027\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L01/video/L01_V005.mp4\n",
      "[TransNetV2] Processing video frames 29024/29024\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L01/video/L01_V006.mp4\n",
      "[TransNetV2] Processing video frames 24946/24946\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L01/video/L01_V007.mp4\n",
      "[TransNetV2] Processing video frames 25678/25678\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L01/video/L01_V008.mp4\n",
      "[TransNetV2] Processing video frames 29647/29647\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L01/video/L01_V009.mp4\n",
      "[TransNetV2] Processing video frames 29173/29173\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L01/video/L01_V010.mp4\n",
      "[TransNetV2] Processing video frames 25567/25567\n",
      "   ...Processed 10/184 scenes.\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L01/video/L01_V011.mp4\n",
      "[TransNetV2] Processing video frames 28843/28843\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L01/video/L01_V012.mp4\n",
      "[TransNetV2] Processing video frames 29315/29315\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L01/video/L01_V013.mp4\n",
      "[TransNetV2] Processing video frames 30043/30043\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L01/video/L01_V014.mp4\n",
      "[TransNetV2] Processing video frames 24820/24820\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L01/video/L01_V015.mp4\n",
      "[TransNetV2] Processing video frames 28551/28551\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L01/video/L01_V016.mp4\n",
      "[TransNetV2] Processing video frames 23002/23002\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L01/video/L01_V017.mp4\n",
      "[TransNetV2] Processing video frames 30437/30437\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L01/video/L01_V018.mp4\n",
      "[TransNetV2] Processing video frames 28676/28676\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L01/video/L01_V019.mp4\n",
      "[TransNetV2] Processing video frames 27355/27355\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L01/video/L01_V020.mp4\n",
      "[TransNetV2] Processing video frames 31489/31489\n",
      "   ...Processed 20/184 scenes.\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L01/video/L01_V021.mp4\n",
      "[TransNetV2] Processing video frames 26587/26587\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L01/video/L01_V022.mp4\n",
      "[TransNetV2] Processing video frames 33266/33266\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L01/video/L01_V023.mp4\n",
      "[TransNetV2] Processing video frames 28881/28881\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L01/video/L01_V024.mp4\n",
      "[TransNetV2] Processing video frames 30342/30342\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L01/video/L01_V025.mp4\n",
      "[TransNetV2] Processing video frames 24216/24216\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L01/video/L01_V026.mp4\n",
      "[TransNetV2] Processing video frames 27566/27566\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L01/video/L01_V027.mp4\n",
      "[TransNetV2] Processing video frames 28695/28695\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L01/video/L01_V028.mp4\n",
      "[TransNetV2] Processing video frames 29578/29578\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L01/video/L01_V029.mp4\n",
      "[TransNetV2] Processing video frames 27290/27290\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L01/video/L01_V030.mp4\n",
      "[TransNetV2] Processing video frames 32115/32115\n",
      "   ...Processed 30/184 scenes.\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L01/video/L01_V031.mp4\n",
      "[TransNetV2] Processing video frames 34673/34673\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L02/video/L02_V001.mp4\n",
      "[TransNetV2] Processing video frames 29967/29967\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L02/video/L02_V002.mp4\n",
      "[TransNetV2] Processing video frames 28338/28338\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L02/video/L02_V003.mp4\n",
      "[TransNetV2] Processing video frames 28682/28682\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L02/video/L02_V004.mp4\n",
      "[TransNetV2] Processing video frames 33897/33897\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L02/video/L02_V005.mp4\n",
      "[TransNetV2] Processing video frames 29157/29157\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L02/video/L02_V006.mp4\n",
      "[TransNetV2] Processing video frames 25318/25318\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L02/video/L02_V007.mp4\n",
      "[TransNetV2] Processing video frames 27637/27637\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L02/video/L02_V008.mp4\n",
      "[TransNetV2] Processing video frames 26342/26342\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L02/video/L02_V009.mp4\n",
      "[TransNetV2] Processing video frames 27996/27996\n",
      "   ...Processed 40/184 scenes.\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L02/video/L02_V010.mp4\n",
      "[TransNetV2] Processing video frames 31593/31593\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L02/video/L02_V011.mp4\n",
      "[TransNetV2] Processing video frames 29006/29006\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L02/video/L02_V012.mp4\n",
      "[TransNetV2] Processing video frames 28906/28906\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L02/video/L02_V013.mp4\n",
      "[TransNetV2] Processing video frames 28713/28713\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L02/video/L02_V014.mp4\n",
      "[TransNetV2] Processing video frames 29591/29591\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L02/video/L02_V015.mp4\n",
      "[TransNetV2] Processing video frames 26623/26623\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L02/video/L02_V016.mp4\n",
      "[TransNetV2] Processing video frames 27082/27082\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L02/video/L02_V017.mp4\n",
      "[TransNetV2] Processing video frames 29028/29028\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L02/video/L02_V018.mp4\n",
      "[TransNetV2] Processing video frames 26642/26642\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L02/video/L02_V019.mp4\n",
      "[TransNetV2] Processing video frames 28573/28573\n",
      "   ...Processed 50/184 scenes.\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L02/video/L02_V020.mp4\n",
      "[TransNetV2] Processing video frames 22825/22825\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L02/video/L02_V021.mp4\n",
      "[TransNetV2] Processing video frames 32318/32318\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L02/video/L02_V022.mp4\n",
      "[TransNetV2] Processing video frames 29866/29866\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L02/video/L02_V023.mp4\n",
      "[TransNetV2] Processing video frames 30079/30079\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L02/video/L02_V024.mp4\n",
      "[TransNetV2] Processing video frames 27269/27269\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L02/video/L02_V025.mp4\n",
      "[TransNetV2] Processing video frames 30291/30291\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L02/video/L02_V026.mp4\n",
      "[TransNetV2] Processing video frames 33349/33349\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L02/video/L02_V027.mp4\n",
      "[TransNetV2] Processing video frames 32416/32416\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L02/video/L02_V028.mp4\n",
      "[TransNetV2] Processing video frames 29217/29217\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L02/video/L02_V029.mp4\n",
      "[TransNetV2] Processing video frames 32189/32189\n",
      "   ...Processed 60/184 scenes.\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L02/video/L02_V030.mp4\n",
      "[TransNetV2] Processing video frames 30358/30358\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L02/video/L02_V031.mp4\n",
      "[TransNetV2] Processing video frames 35915/35915\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L03/video/L03_V001.mp4\n",
      "[TransNetV2] Processing video frames 28401/28401\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L03/video/L03_V002.mp4\n",
      "[TransNetV2] Processing video frames 32592/32592\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L03/video/L03_V003.mp4\n",
      "[TransNetV2] Processing video frames 27150/27150\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L03/video/L03_V004.mp4\n",
      "[TransNetV2] Processing video frames 27777/27777\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L03/video/L03_V005.mp4\n",
      "[TransNetV2] Processing video frames 29312/29312\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L03/video/L03_V006.mp4\n",
      "[TransNetV2] Processing video frames 27589/27589\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L03/video/L03_V007.mp4\n",
      "[TransNetV2] Processing video frames 25881/25881\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L03/video/L03_V008.mp4\n",
      "[TransNetV2] Processing video frames 28788/28788\n",
      "   ...Processed 70/184 scenes.\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L03/video/L03_V009.mp4\n",
      "[TransNetV2] Processing video frames 33549/33549\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L03/video/L03_V010.mp4\n",
      "[TransNetV2] Processing video frames 31284/31284\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L03/video/L03_V011.mp4\n",
      "[TransNetV2] Processing video frames 27499/27499\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L03/video/L03_V012.mp4\n",
      "[TransNetV2] Processing video frames 25366/25366\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L03/video/L03_V013.mp4\n",
      "[TransNetV2] Processing video frames 25356/25356\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L03/video/L03_V014.mp4\n",
      "[TransNetV2] Processing video frames 31930/31930\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L03/video/L03_V015.mp4\n",
      "[TransNetV2] Processing video frames 30854/30854\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L03/video/L03_V016.mp4\n",
      "[TransNetV2] Processing video frames 29665/29665\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L03/video/L03_V017.mp4\n",
      "[TransNetV2] Processing video frames 26930/26930\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L03/video/L03_V018.mp4\n",
      "[TransNetV2] Processing video frames 26444/26444\n",
      "   ...Processed 80/184 scenes.\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L03/video/L03_V019.mp4\n",
      "[TransNetV2] Processing video frames 27485/27485\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L03/video/L03_V020.mp4\n",
      "[TransNetV2] Processing video frames 28755/28755\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L03/video/L03_V021.mp4\n",
      "[TransNetV2] Processing video frames 27899/27899\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L03/video/L03_V022.mp4\n",
      "[TransNetV2] Processing video frames 24871/24871\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L03/video/L03_V023.mp4\n",
      "[TransNetV2] Processing video frames 30827/30827\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L03/video/L03_V024.mp4\n",
      "[TransNetV2] Processing video frames 29701/29701\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L03/video/L03_V025.mp4\n",
      "[TransNetV2] Processing video frames 31840/31840\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L03/video/L03_V026.mp4\n",
      "[TransNetV2] Processing video frames 25402/25402\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L03/video/L03_V027.mp4\n",
      "[TransNetV2] Processing video frames 27677/27677\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L03/video/L03_V028.mp4\n",
      "[TransNetV2] Processing video frames 26581/26581\n",
      "   ...Processed 90/184 scenes.\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L03/video/L03_V029.mp4\n",
      "[TransNetV2] Processing video frames 28940/28940\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L03/video/L03_V030.mp4\n",
      "[TransNetV2] Processing video frames 27984/27984\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L04/video/L04_V001.mp4\n",
      "[TransNetV2] Processing video frames 30581/30581\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L04/video/L04_V002.mp4\n",
      "[TransNetV2] Processing video frames 32298/32298\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L04/video/L04_V003.mp4\n",
      "[TransNetV2] Processing video frames 26346/26346\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L04/video/L04_V004.mp4\n",
      "[TransNetV2] Processing video frames 33458/33458\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L04/video/L04_V005.mp4\n",
      "[TransNetV2] Processing video frames 32841/32841\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L04/video/L04_V006.mp4\n",
      "[TransNetV2] Processing video frames 24602/24602\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L04/video/L04_V007.mp4\n",
      "[TransNetV2] Processing video frames 30095/30095\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L04/video/L04_V008.mp4\n",
      "[TransNetV2] Processing video frames 27701/27701\n",
      "   ...Processed 100/184 scenes.\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L04/video/L04_V009.mp4\n",
      "[TransNetV2] Processing video frames 28819/28819\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L04/video/L04_V010.mp4\n",
      "[TransNetV2] Processing video frames 32281/32281\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L04/video/L04_V011.mp4\n",
      "[TransNetV2] Processing video frames 27584/27584\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L04/video/L04_V012.mp4\n",
      "[TransNetV2] Processing video frames 28886/28886\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L04/video/L04_V013.mp4\n",
      "[TransNetV2] Processing video frames 31854/31854\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L04/video/L04_V014.mp4\n",
      "[TransNetV2] Processing video frames 32382/32382\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L04/video/L04_V015.mp4\n",
      "[TransNetV2] Processing video frames 29062/29062\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L04/video/L04_V016.mp4\n",
      "[TransNetV2] Processing video frames 30802/30802\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L04/video/L04_V017.mp4\n",
      "[TransNetV2] Processing video frames 24752/24752\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L04/video/L04_V018.mp4\n",
      "[TransNetV2] Processing video frames 33282/33282\n",
      "   ...Processed 110/184 scenes.\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L04/video/L04_V019.mp4\n",
      "[TransNetV2] Processing video frames 31257/31257\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L04/video/L04_V020.mp4\n",
      "[TransNetV2] Processing video frames 29390/29390\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L04/video/L04_V021.mp4\n",
      "[TransNetV2] Processing video frames 25788/25788\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L04/video/L04_V022.mp4\n",
      "[TransNetV2] Processing video frames 32205/32205\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L04/video/L04_V023.mp4\n",
      "[TransNetV2] Processing video frames 28380/28380\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L04/video/L04_V024.mp4\n",
      "[TransNetV2] Processing video frames 32921/32921\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L04/video/L04_V025.mp4\n",
      "[TransNetV2] Processing video frames 31429/31429\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L04/video/L04_V026.mp4\n",
      "[TransNetV2] Processing video frames 29113/29113\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L04/video/L04_V027.mp4\n",
      "[TransNetV2] Processing video frames 26745/26745\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L04/video/L04_V028.mp4\n",
      "[TransNetV2] Processing video frames 30712/30712\n",
      "   ...Processed 120/184 scenes.\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L04/video/L04_V029.mp4\n",
      "[TransNetV2] Processing video frames 29635/29635\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L04/video/L04_V030.mp4\n",
      "[TransNetV2] Processing video frames 29562/29562\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L05/video/L05_V001.mp4\n",
      "[TransNetV2] Processing video frames 29176/29176\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L05/video/L05_V002.mp4\n",
      "[TransNetV2] Processing video frames 27308/27308\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L05/video/L05_V003.mp4\n",
      "[TransNetV2] Processing video frames 29623/29623\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L05/video/L05_V004.mp4\n",
      "[TransNetV2] Processing video frames 27181/27181\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L05/video/L05_V005.mp4\n",
      "[TransNetV2] Processing video frames 25942/25942\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L05/video/L05_V006.mp4\n",
      "[TransNetV2] Processing video frames 33171/33171\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L05/video/L05_V007.mp4\n",
      "[TransNetV2] Processing video frames 26134/26134\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L05/video/L05_V008.mp4\n",
      "[TransNetV2] Processing video frames 32094/32094\n",
      "   ...Processed 130/184 scenes.\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L05/video/L05_V009.mp4\n",
      "[TransNetV2] Processing video frames 27944/27944\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L05/video/L05_V010.mp4\n",
      "[TransNetV2] Processing video frames 25687/25687\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L05/video/L05_V011.mp4\n",
      "[TransNetV2] Processing video frames 27239/27239\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L05/video/L05_V012.mp4\n",
      "[TransNetV2] Processing video frames 28914/28914\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L05/video/L05_V013.mp4\n",
      "[TransNetV2] Processing video frames 33960/33960\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L05/video/L05_V014.mp4\n",
      "[TransNetV2] Processing video frames 27648/27648\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L05/video/L05_V015.mp4\n",
      "[TransNetV2] Processing video frames 31247/31247\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L05/video/L05_V016.mp4\n",
      "[TransNetV2] Processing video frames 29566/29566\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L05/video/L05_V017.mp4\n",
      "[TransNetV2] Processing video frames 29579/29579\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L05/video/L05_V018.mp4\n",
      "[TransNetV2] Processing video frames 28351/28351\n",
      "   ...Processed 140/184 scenes.\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L05/video/L05_V019.mp4\n",
      "[TransNetV2] Processing video frames 29384/29384\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L05/video/L05_V020.mp4\n",
      "[TransNetV2] Processing video frames 27247/27247\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L05/video/L05_V021.mp4\n",
      "[TransNetV2] Processing video frames 23213/23213\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L05/video/L05_V022.mp4\n",
      "[TransNetV2] Processing video frames 30486/30486\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L05/video/L05_V023.mp4\n",
      "[TransNetV2] Processing video frames 30300/30300\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L05/video/L05_V024.mp4\n",
      "[TransNetV2] Processing video frames 30843/30843\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L05/video/L05_V025.mp4\n",
      "[TransNetV2] Processing video frames 26361/26361\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L05/video/L05_V026.mp4\n",
      "[TransNetV2] Processing video frames 25454/25454\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L05/video/L05_V027.mp4\n",
      "[TransNetV2] Processing video frames 28448/28448\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L05/video/L05_V028.mp4\n",
      "[TransNetV2] Processing video frames 27906/27906\n",
      "   ...Processed 150/184 scenes.\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L05/video/L05_V029.mp4\n",
      "[TransNetV2] Processing video frames 28321/28321\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L05/video/L05_V030.mp4\n",
      "[TransNetV2] Processing video frames 28823/28823\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L05/video/L05_V031.mp4\n",
      "[TransNetV2] Processing video frames 35891/35891\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L06/video/L06_V001.mp4\n",
      "[TransNetV2] Processing video frames 28823/28823\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L06/video/L06_V002.mp4\n",
      "[TransNetV2] Processing video frames 27979/27979\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L06/video/L06_V003.mp4\n",
      "[TransNetV2] Processing video frames 36839/36839\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L06/video/L06_V004.mp4\n",
      "[TransNetV2] Processing video frames 32988/32988\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L06/video/L06_V005.mp4\n",
      "[TransNetV2] Processing video frames 25618/25618\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L06/video/L06_V006.mp4\n",
      "[TransNetV2] Processing video frames 30053/30053\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L06/video/L06_V007.mp4\n",
      "[TransNetV2] Processing video frames 34191/34191\n",
      "   ...Processed 160/184 scenes.\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L06/video/L06_V008.mp4\n",
      "[TransNetV2] Processing video frames 31341/31341\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L06/video/L06_V009.mp4\n",
      "[TransNetV2] Processing video frames 33012/33012\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L06/video/L06_V010.mp4\n",
      "[TransNetV2] Processing video frames 30090/30090\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L06/video/L06_V011.mp4\n",
      "[TransNetV2] Processing video frames 28515/28515\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L06/video/L06_V012.mp4\n",
      "[TransNetV2] Processing video frames 30872/30872\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L06/video/L06_V013.mp4\n",
      "[TransNetV2] Processing video frames 34947/34947\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L06/video/L06_V014.mp4\n",
      "[TransNetV2] Processing video frames 29754/29754\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L06/video/L06_V015.mp4\n",
      "[TransNetV2] Processing video frames 31045/31045\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L06/video/L06_V016.mp4\n",
      "[TransNetV2] Processing video frames 30600/30600\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L06/video/L06_V017.mp4\n",
      "[TransNetV2] Processing video frames 32424/32424\n",
      "   ...Processed 170/184 scenes.\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L06/video/L06_V018.mp4\n",
      "[TransNetV2] Processing video frames 27374/27374\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L06/video/L06_V019.mp4\n",
      "[TransNetV2] Processing video frames 28993/28993\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L06/video/L06_V020.mp4\n",
      "[TransNetV2] Processing video frames 29553/29553\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L06/video/L06_V021.mp4\n",
      "[TransNetV2] Processing video frames 27206/27206\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L06/video/L06_V022.mp4\n",
      "[TransNetV2] Processing video frames 33210/33210\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L06/video/L06_V023.mp4\n",
      "[TransNetV2] Processing video frames 32204/32204\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L06/video/L06_V024.mp4\n",
      "[TransNetV2] Processing video frames 28798/28798\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L06/video/L06_V025.mp4\n",
      "[TransNetV2] Processing video frames 29724/29724\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L06/video/L06_V026.mp4\n",
      "[TransNetV2] Processing video frames 31851/31851\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L06/video/L06_V027.mp4\n",
      "[TransNetV2] Processing video frames 33448/33448\n",
      "   ...Processed 180/184 scenes.\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L06/video/L06_V028.mp4\n",
      "[TransNetV2] Processing video frames 33093/33093\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L06/video/L06_V029.mp4\n",
      "[TransNetV2] Processing video frames 33673/33673\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L06/video/L06_V030.mp4\n",
      "[TransNetV2] Processing video frames 32594/32594\n",
      "[TransNetV2] Extracting frames from /kaggle/input/aic2024-videos-part1-1/Videos_L06/video/L06_V031.mp4\n",
      "[TransNetV2] Processing video frames 31844/31844\n",
      "‚úÖ Scene Detection FINISHED! Created 184 json files.\n",
      "CPU times: user 26min 12s, sys: 3min 54s, total: 30min 7s\n",
      "Wall time: 3h 12min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import os\n",
    "import json\n",
    "\n",
    "save_dir = '/kaggle/working/scenes'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# L·∫•y danh s√°ch video t·ª´ config ·ªü Cell 4\n",
    "videos_to_process = all_batches_info[BATCH_ID][MEMBER_ID]\n",
    "print(f\"üöÄ Start processing {len(videos_to_process)} videos for Scene Detection...\")\n",
    "\n",
    "count = 0\n",
    "for i, video_path in enumerate(videos_to_process):\n",
    "    try:\n",
    "        # --- LOGIC FIX L·ªñI T√äN FILE ---\n",
    "        filename = video_path.split('/')[-1]\n",
    "        parts = filename.split('_')\n",
    "        \n",
    "        if len(parts) >= 2:\n",
    "            # Chu·∫©n: L01_V001.mp4 -> Batch: L01\n",
    "            video_batch = parts[0]\n",
    "            video_name = \"_\".join(parts[1:])\n",
    "        else:\n",
    "            # L·ªói: test.mp4 -> L·∫•y Batch t·ª´ t√™n th∆∞ m·ª•c cha (Videos_L01)\n",
    "            parent_dir = video_path.split('/')[-3] \n",
    "            if \"Videos_\" in parent_dir:\n",
    "                video_batch = parent_dir.split('_')[-1]\n",
    "            else:\n",
    "                video_batch = \"Uncategorized\"\n",
    "            video_name = filename\n",
    "\n",
    "        video_name = video_name.replace('.mp4', '')\n",
    "        \n",
    "        # T·∫°o th∆∞ m·ª•c con: /scenes/L01\n",
    "        batch_save_dir = os.path.join(save_dir, video_batch)\n",
    "        os.makedirs(batch_save_dir, exist_ok=True)\n",
    "        \n",
    "        json_path = f\"{batch_save_dir}/{video_name}.json\"\n",
    "        \n",
    "        # N·∫øu file ƒë√£ c√≥ r·ªìi th√¨ b·ªè qua (ƒë·ªÉ resume n·∫øu b·ªã ng·∫Øt)\n",
    "        if os.path.exists(json_path):\n",
    "            continue\n",
    "\n",
    "        # --- G·ªåI TRANSNET MODEL ---\n",
    "        _, single_frame_predictions, _ = model.predict_video(video_path)\n",
    "        scenes = model.predictions_to_scenes(single_frame_predictions)\n",
    "        \n",
    "        with open(json_path, 'w') as f:\n",
    "            json.dump(scenes.tolist(), f)\n",
    "            \n",
    "        count += 1\n",
    "        if count % 10 == 0:\n",
    "            print(f\"   ...Processed {count}/{len(videos_to_process)} scenes.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error on {video_path}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"‚úÖ Scene Detection FINISHED! Created {count} json files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5783e2a9",
   "metadata": {
    "papermill": {
     "duration": 0.842409,
     "end_time": "2025-12-10T00:52:12.182247",
     "exception": false,
     "start_time": "2025-12-10T00:52:11.339838",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **4. Extract frames from scenes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7f630ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T00:52:13.882065Z",
     "iopub.status.busy": "2025-12-10T00:52:13.881736Z",
     "iopub.status.idle": "2025-12-10T00:52:13.888249Z",
     "shell.execute_reply": "2025-12-10T00:52:13.887541Z"
    },
    "papermill": {
     "duration": 0.854254,
     "end_time": "2025-12-10T00:52:13.889915",
     "exception": false,
     "start_time": "2025-12-10T00:52:13.035661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CELL 7: Optimized Save Frames with Compression\n",
    "def save_frames(video_path: str, frame_numbers: np.ndarray, save_dir: str):\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    frame_numbers = np.sort(np.unique(frame_numbers))\n",
    "    \n",
    "    frame_idx = 0\n",
    "    if len(frame_numbers) == 0:\n",
    "        video.release()\n",
    "        return\n",
    "\n",
    "    frame_it = frame_numbers[frame_idx]\n",
    "    max_frame = frame_numbers[-1] + 1\n",
    "    \n",
    "    for i in range(max_frame):\n",
    "        ret, frame = video.read()       \n",
    "        if not ret: break\n",
    "            \n",
    "        if i == frame_it:\n",
    "            filename = \"{}/{:0>4d}.jpg\".format(f'{save_dir}', i)\n",
    "            # N√©n ·∫£nh JPG ch·∫•t l∆∞·ª£ng 80-85 ƒë·ªÉ ti·∫øt ki·ªám dung l∆∞·ª£ng\n",
    "            cv2.imwrite(filename, frame, [int(cv2.IMWRITE_JPEG_QUALITY), 80])\n",
    "            \n",
    "            frame_idx += 1\n",
    "            if frame_idx < len(frame_numbers):\n",
    "                frame_it = frame_numbers[frame_idx]\n",
    "            else:\n",
    "                break\n",
    "    video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb62c386",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T00:52:15.593194Z",
     "iopub.status.busy": "2025-12-10T00:52:15.592856Z",
     "iopub.status.idle": "2025-12-10T01:21:00.970450Z",
     "shell.execute_reply": "2025-12-10T01:21:00.969545Z"
    },
    "papermill": {
     "duration": 1726.984402,
     "end_time": "2025-12-10T01:21:01.727654",
     "exception": false,
     "start_time": "2025-12-10T00:52:14.743252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting Extraction for Batches: ['L06']\n",
      "üíæ Saving to: keyframes_part1_L06.zip\n",
      "üëâ Processing Batch L06 (31 videos)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bdbbc49523c43e68584ddbd1a74f5f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Zipping L06:   0%|          | 0/31 [00:00<?, ?vid/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Closing Zip file...\n",
      "üéâ DONE L06! File created: keyframes_part1_L06.zip (3.71 GB)\n"
     ]
    }
   ],
   "source": [
    "# --- CELL: Extract Keyframes cho L06 (Batch cu·ªëi) ---\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import cv2\n",
    "import os\n",
    "import json\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "# ==========================================\n",
    "# ‚öôÔ∏è C·∫§U H√åNH RI√äNG CHO L06\n",
    "# ==========================================\n",
    "TARGET_BATCHES = ['L06'] \n",
    "OUTPUT_ZIP_NAME = 'keyframes_part1_L06.zip'\n",
    "# ==========================================\n",
    "\n",
    "# ƒê∆∞·ªùng d·∫´n l√†m vi·ªác\n",
    "work_dir = '/kaggle/working'\n",
    "scene_json_dirs = '/kaggle/working/scenes'\n",
    "final_zip_path = os.path.join(work_dir, OUTPUT_ZIP_NAME)\n",
    "\n",
    "# D·ªçn d·∫πp file c≈© n·∫øu c√≥ ƒë·ªÉ tr√°nh l·ªói\n",
    "if os.path.exists(final_zip_path):\n",
    "    print(f\"‚ö†Ô∏è Found existing {OUTPUT_ZIP_NAME}, removing to start fresh...\")\n",
    "    os.remove(final_zip_path)\n",
    "\n",
    "# --- H√ÄM CHI·∫æN L∆Ø·ª¢C FRAME ---\n",
    "def get_adaptive_frames(scenes):\n",
    "    frames_to_capture = []\n",
    "    for start, end in scenes:\n",
    "        duration = end - start\n",
    "        if duration <= 1: continue \n",
    "        if duration < 25: \n",
    "            frames_to_capture.append((start + end) // 2)\n",
    "        elif duration < 150: \n",
    "            frames_to_capture.extend([start, (start + end) // 2, end - 1])\n",
    "        else: \n",
    "            step = 50 \n",
    "            sampled = range(start, end, step)\n",
    "            frames_to_capture.extend(sampled)\n",
    "            if (end - 1) not in frames_to_capture:\n",
    "                frames_to_capture.append(end - 1)\n",
    "    return sorted(list(set(frames_to_capture)))\n",
    "\n",
    "# --- H√ÄM KI·ªÇM TRA DUNG L∆Ø·ª¢NG TR·ªêNG ---\n",
    "def get_free_space_gb():\n",
    "    total, used, free = shutil.disk_usage(work_dir)\n",
    "    return free / (1024**3)\n",
    "\n",
    "# --- V√íNG L·∫∂P CH√çNH ---\n",
    "print(f\"üöÄ Starting Extraction for Batches: {TARGET_BATCHES}\")\n",
    "print(f\"üíæ Saving to: {OUTPUT_ZIP_NAME}\")\n",
    "\n",
    "# M·ªü file Zip v·ªõi ch·∫ø ƒë·ªô 'w' (Direct Write)\n",
    "with zipfile.ZipFile(final_zip_path, 'w', zipfile.ZIP_DEFLATED) as zf:\n",
    "    \n",
    "    stop_processing = False\n",
    "    \n",
    "    for key in TARGET_BATCHES:\n",
    "        if stop_processing: break\n",
    "        \n",
    "        # Ki·ªÉm tra batch c√≥ t·ªìn t·∫°i kh√¥ng\n",
    "        if key not in all_video_paths:\n",
    "            print(f\"‚ö†Ô∏è Batch {key} not found. Skipping.\")\n",
    "            continue\n",
    "            \n",
    "        video_paths_dict = all_video_paths[key]\n",
    "        video_ids = sorted(video_paths_dict.keys())\n",
    "        \n",
    "        print(f\"üëâ Processing Batch {key} ({len(video_ids)} videos)...\")\n",
    "        \n",
    "        pbar = tqdm(video_ids, desc=f\"Zipping {key}\", unit=\"vid\")\n",
    "        \n",
    "        for video_id in pbar:\n",
    "            # --- SAFETY CHECK: D·ª´ng n·∫øu ·ªï c·ª©ng < 1GB ---\n",
    "            if get_free_space_gb() < 1.0:\n",
    "                print(f\"\\nüõë CRITICAL: Disk space low ({get_free_space_gb():.2f} GB left). Stopping.\")\n",
    "                stop_processing = True\n",
    "                break\n",
    "\n",
    "            # Logic t√¨m file Scene JSON\n",
    "            scene_path_v1 = f'{scene_json_dirs}/{key}/{key}_{video_id}.json'\n",
    "            scene_path_v2 = f'{scene_json_dirs}/{key}/{video_id}.json'\n",
    "            final_scene_path = scene_path_v1 if os.path.exists(scene_path_v1) else (scene_path_v2 if os.path.exists(scene_path_v2) else None)\n",
    "            \n",
    "            if not final_scene_path: continue\n",
    "\n",
    "            try:\n",
    "                with open(final_scene_path) as f:\n",
    "                    scenes = json.load(f)\n",
    "                scenes = np.array([list(row) for row in scenes])\n",
    "                if len(scenes) == 0: continue\n",
    "\n",
    "                frame_numbers = get_adaptive_frames(scenes)\n",
    "                if not frame_numbers: continue\n",
    "                \n",
    "                # Direct Read -> Encode -> Zip\n",
    "                video_path = video_paths_dict[video_id]\n",
    "                vid_cap = cv2.VideoCapture(video_path)\n",
    "                \n",
    "                f_idx = 0\n",
    "                max_f = frame_numbers[-1] + 1\n",
    "                \n",
    "                for i in range(max_f):\n",
    "                    ret, frame = vid_cap.read()\n",
    "                    if not ret: break\n",
    "                    \n",
    "                    if i == frame_numbers[f_idx]:\n",
    "                        # Encode JPG (Quality 80) v√†o RAM\n",
    "                        ret_enc, buffer = cv2.imencode('.jpg', frame, [int(cv2.IMWRITE_JPEG_QUALITY), 80])\n",
    "                        \n",
    "                        if ret_enc:\n",
    "                            # Save path: keyframes/L06/V001/0001.jpg\n",
    "                            zip_entry_name = f\"keyframes/{key}/{video_id}/{i:04d}.jpg\"\n",
    "                            zf.writestr(zip_entry_name, buffer.tobytes())\n",
    "                        \n",
    "                        f_idx += 1\n",
    "                        if f_idx >= len(frame_numbers): break\n",
    "                            \n",
    "                vid_cap.release()\n",
    "                \n",
    "            except Exception as e:\n",
    "                # print(f\"Error {video_id}: {e}\")\n",
    "                pass\n",
    "\n",
    "print(f\"üì¶ Closing Zip file...\")\n",
    "final_size = os.path.getsize(final_zip_path) / (1024**3) if os.path.exists(final_zip_path) else 0\n",
    "print(f\"üéâ DONE L06! File created: {OUTPUT_ZIP_NAME} ({final_size:.2f} GB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a989446",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T01:21:03.374375Z",
     "iopub.status.busy": "2025-12-10T01:21:03.373994Z",
     "iopub.status.idle": "2025-12-10T01:21:03.378417Z",
     "shell.execute_reply": "2025-12-10T01:21:03.377627Z"
    },
    "papermill": {
     "duration": 0.808864,
     "end_time": "2025-12-10T01:21:03.380012",
     "exception": false,
     "start_time": "2025-12-10T01:21:02.571148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %cd /kaggle/working/\n",
    "\n",
    "# print(\"üì¶ Zipping Scenes...\")\n",
    "# !zip -rq scenes.zip scenes/\n",
    "\n",
    "# import os\n",
    "# def get_size(path):\n",
    "#     if os.path.exists(path):\n",
    "#         size = os.path.getsize(path) / (1024 * 1024 * 1024)\n",
    "#         print(f\"   -> {path}: {size:.2f} GB\")\n",
    "#     else:\n",
    "#         print(f\"   -> {path}: NOT FOUND\")\n",
    "\n",
    "# print(\"üìä Checking Output Sizes:\")\n",
    "# get_size('keyframes.zip')\n",
    "# get_size('scenes.zip')\n",
    "\n",
    "# from IPython.display import FileLink\n",
    "# print(\"\\n‚¨áÔ∏è DOWNLOAD LINKS:\")\n",
    "# display(FileLink('keyframes.zip'))\n",
    "# display(FileLink('scenes.zip'))\n",
    "\n",
    "# # Cleanup (Optional)\n",
    "# # !rm -rf scenes\n",
    "# # !rm -rf temp_keyframes"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5573261,
     "sourceId": 9216514,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30762,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 13307.59789,
   "end_time": "2025-12-10T01:21:07.155248",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-09T21:39:19.557358",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "1e51a2e7adcd4be3973099d0c8c35f54": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "2bdbbc49523c43e68584ddbd1a74f5f6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e17d9fd89c5d4af18e57bef5ad140cad",
        "IPY_MODEL_f178b77484f94656bc93471ee945911f",
        "IPY_MODEL_fe4351ccf9c44e8fb34b17aaf8d9c123"
       ],
       "layout": "IPY_MODEL_8da829760942477385b1402b410afed4"
      }
     },
     "85b448a3eaad4a8ca4afcb1488cb70d7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "8da829760942477385b1402b410afed4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "92d4d731aa7c4ea6b7db69789c41136b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a832a077830e4bb2b7fa68c87ffe9615": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "af082ebfb7c2449fac18c128f1322845": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bc27f825a54749c4bdf23093d84fa928": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e17d9fd89c5d4af18e57bef5ad140cad": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_bc27f825a54749c4bdf23093d84fa928",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_1e51a2e7adcd4be3973099d0c8c35f54",
       "value": "Zipping‚ÄáL06:‚Äá100%"
      }
     },
     "f178b77484f94656bc93471ee945911f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_92d4d731aa7c4ea6b7db69789c41136b",
       "max": 31.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a832a077830e4bb2b7fa68c87ffe9615",
       "value": 31.0
      }
     },
     "fe4351ccf9c44e8fb34b17aaf8d9c123": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_af082ebfb7c2449fac18c128f1322845",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_85b448a3eaad4a8ca4afcb1488cb70d7",
       "value": "‚Äá31/31‚Äá[28:45&lt;00:00,‚Äá57.43s/vid]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
